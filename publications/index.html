<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Ignacio Peis </title> <meta name="author" content="Ignacio Peis"> <meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar."> <meta name="keywords" content="artificial intellingence, research, deep generative models"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon.png?53627c77d2df51f1004b9f74301af955"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ipeis.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Ignacio</span> Peis </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p> </header> <article> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#333333"> <a href="">preprint</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/source_to_field-480.webp 480w,/assets/img/publication_preview/source_to_field-800.webp 800w,/assets/img/publication_preview/source_to_field-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/source_to_field.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="source_to_field.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="james2024scalable" class="col-sm-8"> <div class="title">Scalable physical source-to-field inference with hypernetworks</div> <div class="author"> Berian James, Stefan Pollok, <em>Ignacio Peis</em>, <a href="https://frellsen.org/" rel="external nofollow noopener" target="_blank">Jes Frellsen</a>, and Rasmus Bjørk </div> <div class="periodical"> <em>arXiv preprint arXiv:2405.05981</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2405.05981" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2405.05981.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">james2024scalable</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Scalable physical source-to-field inference with hypernetworks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{James, Berian and Pollok, Stefan and Peis, Ignacio and Frellsen, Jes and Bj{\o}rk, Rasmus}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2405.05981}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">PhD Thesis</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/phd_thesis-480.webp 480w,/assets/img/publication_preview/phd_thesis-800.webp 800w,/assets/img/publication_preview/phd_thesis-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/phd_thesis.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="phd_thesis.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="peis2023advanced" class="col-sm-8"> <div class="title">Advanced Inference and Representation Learning Methods in Variational Autoencoders</div> <div class="author"> <em>Ignacio Peis</em> </div> <div class="periodical"> <em>PhD Thesis Dissertation</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://e-archivo.uc3m.es/entities/publication/196ba69d-5b30-4b6e-9b91-d4aede63a6e0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://ipeis.github.io/assets/pdf/PhD_Thesis_Ignacio_Peis_Defense.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://ipeis.github.io/assets/pdf/PhD_Presentation_Ignacio_Peis.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p> Deep Generative Models have gained significant popularity in the Machine Learning research community since the early 2010s. These models allow to generate realistic data by leveraging the power of Deep Neural Networks. The field experienced a significant breakthrough when Variational Autoencoders (VAEs) were introduced. VAEs revolutionized Deep Generative Modeling by providing a scalable and flexible framework that enables the generation of complex data distributions and the learning of potentially interpretable latent representations. They have proven to be a powerful tool in numerous applications, from image, sound and video generation to natural language processing or drug discovery, among others. At their core, VAEs encode natural information into a reduced latent space and decode the learned latent space into new synthetic data. Advanced versions of VAEs have been developed to handle challenges such as handling heterogeneous incomplete data, encoding into hierarchical latent spaces for representing abstract and richer concepts, or modeling sequential data, among others. These advances have expanded the capabilities of VAEs and made them a valuable tool in a wide range of fields. Despite the significant progress made in VAE research, there is still ample room for improvement in their current state-of-the-art. One of the major challenges is improving their approximate inference. VAEs typically assume Gaussian approximations of the posterior distribution of the latent variables in order to make the training objective tractable. The parameters of this approximation are provided by encoder networks. However, this approximation leads to a lower bounded objective, which can degrade the performance of any task that requires samples from the approximate posterior, due to the implicit bias. The second major challenge addressed in this thesis is related to achieving meaningful latent representations, or more broadly, how the latent space disentangles generative factors of variation. Ideally, the latent space would modulate meaningful properties separately within each dimension. However, Maximum Likelihood optimizations require the marginalization of latent variables, leading to non-unique solutions that may or may not achieve this desired disentanglement. Additionally, properties learned at the observation level in VAEs assume that every observation is generated independently, which may not be the case in some scenarios. To address these limitations, more robust VAEs have been developed to learn disentangled properties at the supervised group (also referred to as global) level. These models are capable of generating groups of data with shared properties. The work presented in this doctoral thesis focuses on the development of novel methods for improving the state-of-the-art in VAEs. Specifically, three fundamental challenges are addressed: achieving meaningful global latent representations, obtaining highly-flexible priors for learning more expressive models, and improving current approximate inference methods. As a first main contribution, an innovative technique named UG-VAE from Unsupervised-Global VAE, aims to enhance the ability of VAEs in capturing factors of variations at data (local) and group (global) level. By carefully desigining the encoder and the decoder, and throughout conductive experiments, it is demonstrated that UG-VAE is effective in capturing unsupervised global factors from images. Second, a non-trivial combination of highly-expressive Hierarchical VAEs with robust Markov Chain Monte Carlo inference (specifically Hamiltonian Monte Carlo), for which important issues are successfully resolved, is presented. The resulting model, referred to as the Hierarchical Hamiltonian VAE model for Mixed-type incomplete data (HH-VAEM), addresses the challenges associated with imputing and acquiring heterogeneous missing data. Throughout extensive experiments, it is demonstrated that HH-VAEM outperforms existing one-layered and Gaussian baselines in the tasks of missing data imputation and supervised learning with missing features, thanks to its improved inference and expressivity. Furthermore, another relevant contribution is presented, namely a sampling-based approach for efficiently computing the information gain when missing features are to be acquired with HH-VAEM. This approach leverages the advantages of HH-VAEM and is demonstrated to be effective in the same tasks. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">peis2023advanced</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Advanced Inference and Representation Learning Methods in Variational Autoencoders}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Peis, Ignacio}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{PhD Thesis Dissertation}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="nv">false</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100"> <a href="https://icml.cc/" rel="external nofollow noopener" target="_blank">ICML</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/vamoh-480.webp 480w,/assets/img/publication_preview/vamoh-800.webp 800w,/assets/img/publication_preview/vamoh-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/vamoh.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="vamoh.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="koyuncu2023variational" class="col-sm-8"> <div class="title">Variational Mixture of HyperGenerators for Learning Distributions Over Functions</div> <div class="author"> <a href="https://www.batukoyuncu.com/" rel="external nofollow noopener" target="_blank">Batuhan Koyuncu</a>, <a href="https://is.mpg.de/person/psanchez" rel="external nofollow noopener" target="_blank">Pablo Sanchez-Martin</a>, <em>Ignacio Peis</em>, <a href="https://www.tsc.uc3m.es/~olmos/" rel="external nofollow noopener" target="_blank">Pablo M. Olmos</a>, and <a href="https://ivaleram.github.io/" rel="external nofollow noopener" target="_blank">Isabel Valera</a> </div> <div class="periodical"> <em>In Proceedings of the 40th <b>International Conference on Machine Learning</b></em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.mlr.press/v202/koyuncu23a/koyuncu23a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://icml.cc/virtual/2023/poster/23684" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://github.com/bkoyuncu/vamoh" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://icml.cc/media/PosterPDFs/ICML%202023/23684.png?t=1689852186.8291144" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Poster</a> </div> <div class="abstract hidden"> <p> Recent approaches build on implicit neural representations (INRs) to propose generative models over function spaces. However, they are computationally intensive when dealing with inference tasks, such as missing data imputation, or directly cannot tackle them. In this work, we propose a novel deep generative model, named VAMoH. VAMoH combines the capabilities of modeling continuous functions using INRs and the inference capabilities of Variational Autoencoders (VAEs). In addition, VAMoH relies on a normalizing flow to define the prior, and a mixture of hypernetworks to parametrize the data log-likelihood. This gives VAMoH a high expressive capability and interpretability. Through experiments on a diverse range of data types, such as images, voxels, and climate data, we show that VAMoH can effectively learn rich distributions over continuous functions. Furthermore, it can perform inference-related tasks, such as conditional super-resolution generation and in-painting, as well or better than previous approaches, while being less computationally demanding. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">koyuncu2023variational</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Variational Mixture of HyperGenerators for Learning Distributions Over Functions}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Koyuncu, Batuhan and Sanchez-Martin, Pablo and Peis, Ignacio and Olmos, Pablo M. and Valera, Isabel}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 40th &lt;b&gt;International Conference on Machine Learning&lt;/b&gt;}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100"> <a href="https://neurips.cc/" rel="external nofollow noopener" target="_blank">NeurIPS</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/hhvaem-480.webp 480w,/assets/img/publication_preview/hhvaem-800.webp 800w,/assets/img/publication_preview/hhvaem-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/hhvaem.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="hhvaem.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="peis2022missing" class="col-sm-8"> <div class="title">Missing Data Imputation and Acquisition with Deep Hierarchical Models and Hamiltonian Monte Carlo</div> <div class="author"> <em>Ignacio Peis</em>, <a href="https://chao-ma.org/" rel="external nofollow noopener" target="_blank">Chao Ma</a>, and <a href="https://jmhl.org/" rel="external nofollow noopener" target="_blank">José Miguel Hernández-Lobato</a> </div> <div class="periodical"> <em>In Advances in <b>Neural Information Processing Systems</b> 35</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://papers.nips.cc/paper_files/paper/2022/file/e8dbeb1c947a30576c699e7f5c73d3e3-Supplemental-Conference.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://nips.cc/virtual/2022/poster/53314" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://github.com/ipeis/HH-VAEM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://ipeis.github.io/assets/pdf/NeurIPS_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> <a href="https://ipeis.github.io/assets/pdf/NeurIPS_presentation.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p>Variational Autoencoders (VAEs) have recently been highly successful at imputing and acquiring heterogeneous missing data. However, within this specific application domain, existing VAE methods are restricted by using only one layer of latent variables and strictly Gaussian posterior approximations. To address these limitations, we present HH-VAEM, a Hierarchical VAE model for mixed-type incomplete data that uses Hamiltonian Monte Carlo with automatic hyper-parameter tuning for improved approximate inference. Our experiments show that HH-VAEM outperforms existing baselines in the tasks of missing data imputation and supervised learning with missing features. Finally, we also present a sampling-based approach for efficiently computing the information gain when missing features are to be acquired with HH-VAEM. Our experiments show that this sampling-based approach is superior to alternatives based on Gaussian approximations.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">peis2022missing</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Missing Data Imputation and Acquisition with Deep Hierarchical Models and Hamiltonian Monte Carlo}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Peis, Ignacio and Ma, Chao and Hern{\'a}ndez-Lobato, Jos{\'e} Miguel}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in &lt;b&gt;Neural Information Processing Systems&lt;/b&gt; 35}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff7f00"> <a href="https://www.sciencedirect.com/journal/pattern-recognition" rel="external nofollow noopener" target="_blank">PR</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ugvae-480.webp 480w,/assets/img/publication_preview/ugvae-800.webp 800w,/assets/img/publication_preview/ugvae-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/ugvae.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ugvae.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="PEIS2023109130" class="col-sm-8"> <div class="title">Unsupervised learning of global factors in deep generative models</div> <div class="author"> <em>Ignacio Peis</em>, <a href="https://www.tsc.uc3m.es/~olmos/" rel="external nofollow noopener" target="_blank">Pablo M. Olmos</a>, and <a href="https://www.tsc.uc3m.es/~antonio/antonio_artes/Home.html" rel="external nofollow noopener" target="_blank">Antonio Artés-Rodríguez</a> </div> <div class="periodical"> <em>Pattern Recognition</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/https://doi.org/10.1016/j.patcog.2022.109130" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S0031320322006100" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://www.sciencedirect.com/science/article/pii/S0031320322006100/pdfft?isDTMRedir=true&amp;download=true" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/ipeis/UG-VAE" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>We present a novel deep generative model based on non i.i.d. variational autoencoders that captures global dependencies among observations in a fully unsupervised fashion. In contrast to the recent semi-supervised alternatives for global modeling in deep generative models, our approach combines a mixture model in the local or data-dependent space and a global Gaussian latent variable, which lead us to obtain three particular insights. First, the induced latent global space captures interpretable disentangled representations with no user-defined regularization in the evidence lower bound (as in β-VAE and its generalizations). Second, we show that the model performs domain alignment to find correlations and interpolate between different databases. Finally, we study the ability of the global space to discriminate between groups of observations with non-trivial underlying structures, such as face images with shared attributes or defined sequences of digits images.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">PEIS2023109130</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Unsupervised learning of global factors in deep generative models}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Pattern Recognition}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{134}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{109130}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0031-3203}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.patcog.2022.109130}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Peis, Ignacio and Olmos, Pablo M. and Artés-Rodríguez, Antonio}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#333333"> <a href="https://www.nature.com/srep/" rel="external nofollow noopener" target="_blank">Nature SR</a> </abbr> </div> <div id="peis2020actigraphic" class="col-sm-8"> <div class="title">Actigraphic recording of motor activity in depressed inpatients: a novel computational approach to prediction of clinical course and hospital discharge</div> <div class="author"> <em>Ignacio Peis</em>, Javier-David López-Morı́ñigo, M Mercedes Pérez-Rodrı́guez, Maria-Luisa Barrigón, Marta Ruiz-Gómez, <a href="https://www.tsc.uc3m.es/~antonio/antonio_artes/Home.html" rel="external nofollow noopener" target="_blank">Antonio Artés-Rodríguez</a>, and Enrique Baca-Garcı́a </div> <div class="periodical"> <em>Scientific reports</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.nature.com/articles/s41598-020-74425-x" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Depressed patients present with motor activity abnormalities, which can be easily recorded using actigraphy. The extent to which actigraphically recorded motor activity may predict inpatient clinical course and hospital discharge remains unknown. Participants were recruited from the acute psychiatric inpatient ward at Hospital Rey Juan Carlos (Madrid, Spain). They wore miniature wrist wireless inertial sensors (actigraphs) throughout the admission. We modeled activity levels against the normalized length of admission—‘Progress Towards Discharge’ (PTD)—using a Hierarchical Generalized Linear Regression Model. The estimated date of hospital discharge based on early measures of motor activity and the actual hospital discharge date were compared by a Hierarchical Gaussian Process model. Twenty-three depressed patients (14 females, age: 50.17 ± 12.72 years) were recruited. Activity levels increased during the admission (mean slope of the linear function: 0.12 ± 0.13). For n = 18 inpatients (78.26%) hospitalised for at least 7 days, the mean error of Prediction of Hospital Discharge Date at day 7 was 0.231 ± 22.98 days (95% CI 14.222–14.684). These n = 18 patients were predicted to need, on average, 7 more days in hospital (for a total length of stay of 14 days) (PTD = 0.53). Motor activity increased during the admission in this sample of depressed patients and early patterns of actigraphically recorded activity allowed for accurate prediction of hospital discharge date.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">peis2020actigraphic</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Actigraphic recording of motor activity in depressed inpatients: a novel computational approach to prediction of clinical course and hospital discharge}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Peis, Ignacio and L{\'o}pez-Mor{\'\i}{\~n}igo, Javier-David and P{\'e}rez-Rodr{\'\i}guez, M Mercedes and Barrig{\'o}n, Maria-Luisa and Ruiz-G{\'o}mez, Marta and Artés-Rodríguez, Antonio and Baca-Garc{\'\i}a, Enrique}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Scientific reports}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--11}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Nature Publishing Group}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#9400D3"> <a href="https://www.embs.org/jbhi/" rel="external nofollow noopener" target="_blank">JBHI</a> </abbr> </div> <div id="peis2019deep" class="col-sm-8"> <div class="title">Deep sequential models for suicidal ideation from multiple source data</div> <div class="author"> <em>Ignacio Peis</em>, <a href="https://www.tsc.uc3m.es/~olmos/" rel="external nofollow noopener" target="_blank">Pablo M. Olmos</a>, Constanza Vera-Varela, Marı́a Luisa Barrigón, Philippe Courtet, Enrique Baca-Garcia, and <a href="https://www.tsc.uc3m.es/~antonio/antonio_artes/Home.html" rel="external nofollow noopener" target="_blank">Antonio Artés-Rodríguez</a> </div> <div class="periodical"> <em>IEEE Journal of Biomedical and Health Informatics</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/https://arxiv.org/abs/1911.03522" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/8723181" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>This paper presents a novel method for predicting suicidal ideation from electronic health records (EHR) and ecological momentary assessment (EMA) data using deep sequential models. Both EHR longitudinal data and EMA question forms are defined by asynchronous, variable length, randomly sampled data sequences. In our method, we model each of them with a recurrent neural network, and both sequences are aligned by concatenating the hidden state of each of them using temporal marks. Furthermore, we incorporate attention schemes to improve performance in long sequences and time-independent pre-trained schemes to cope with very short sequences. Using a database of 1023 patients, our experimental results show that the addition of EMA records boosts the system recall to predict the suicidal ideation diagnosis from 48.13% obtained exclusively from EHR-based state-of-the-art methods to 67.78%. Additionally, our method provides interpretability through the t-distributed stochastic neighbor embedding (t-SNE) representation of the latent space. Furthermore, the most relevant input features are identified and interpreted medically.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">peis2019deep</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Deep sequential models for suicidal ideation from multiple source data}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Peis, Ignacio and Olmos, Pablo M. and Vera-Varela, Constanza and Barrig{\'o}n, Mar{\'\i}a Luisa and Courtet, Philippe and Baca-Garcia, Enrique and Artés-Rodríguez, Antonio}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Journal of Biomedical and Health Informatics}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{23}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2286--2293}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="nv">false</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#333333"> <a href="https://www.frontiersin.org/journals/neuroinformatics" rel="external nofollow noopener" target="_blank">Frontiers</a> </abbr> </div> <div id="castillo2017heavy" class="col-sm-8"> <div class="title">A heavy tailed expectation maximization hidden markov random field model with applications to segmentation of MRI</div> <div class="author"> Diego Castillo-Barnes, <em>Ignacio Peis</em>, Francisco J Martı́nez-Murcia, Fermı́n Segovia, Ignacio A. Illán, Juan M. Górriz, Javier Ramı́rez, and Diego Salas-Gonzalez </div> <div class="periodical"> <em>Frontiers in Neuroinformatics</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.frontiersin.org/articles/10.3389/fninf.2017.00066/full" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>A wide range of segmentation approaches assumes that intensity histograms extracted from magnetic resonance images (MRI) have a distribution for each brain tissue that can be modeled by a Gaussian distribution or a mixture of them. Nevertheless, intensity histograms of White Matter and Gray Matter are not symmetric and they exhibit heavy tails. In this work, we present a hidden Markov random field model with expectation maximization (EM-HMRF) modeling the components using the α-stable distribution. The proposed model is a generalization of the widely used EM-HMRF algorithm with Gaussian distributions. We test the α-stable EM-HMRF model in synthetic data and brain MRI data. The proposed methodology presents two main advantages: Firstly, it is more robust to outliers. Secondly, we obtain similar results than using Gaussian when the Gaussian assumption holds. This approach is able to model the spatial dependence between neighboring voxels in tomographic brain MRI.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">castillo2017heavy</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A heavy tailed expectation maximization hidden markov random field model with applications to segmentation of MRI}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Castillo-Barnes, Diego and Peis, Ignacio and Mart{\'\i}nez-Murcia, Francisco J and Segovia, Ferm{\'\i}n and Ill{\'a}n, Ignacio A. and G{\'o}rriz, Juan M. and Ram{\'\i}rez, Javier and Salas-Gonzalez, Diego}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Frontiers in Neuroinformatics}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{66}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Frontiers}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:$red-color-dark"> <a href="https://ieee-npss.org/" rel="external nofollow noopener" target="_blank">NSSMIC</a> </abbr> </div> <div id="peis2016mri" class="col-sm-8"> <div class="title">MRI brain segmentation using hidden Markov random fields with alpha-stable distributions</div> <div class="author"> <em>Ignacio Peis</em>, Francisco J. Martı́nez-Murcia, Fermín Segovia, Juan M. Górriz, Javier Ramı́rez, Elmar W. Lang, and Diego Salas-Gonzalez </div> <div class="periodical"> <em>In 2016 IEEE Nuclear Science Symposium, Medical Imaging Conference and Room-Temperature Semiconductor Detector Workshop (NSS/MIC/RTSD)</em>, 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/8069422" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>A MRI brain image segmentation method using a hidden Markov random fields with heavy-tailed alpha-stable distributions is presented. Each brain tissue is modelled using an alpha-stable distribution. Then, a HMRF is used to include spatial information in the classification model. The Gaussian distribution has been widely used for the modelization of the cerebrospinal fluid, white matter and gray matter. Nevertheless, the alpha-stable distribution has been recently proposed as a more accurate alternative for this task. The alpha-stable distribution is more impulsive and is also able to model the asymmetry and heavy-tails of the histogram of the brain tissues. We have tested the proposed methodology in 18 MR images from the Internet Brain Segmentation Repository. The proposed methodology outperforms the segmentation results obtained when a Gaussian model for the histogram of the brain tissues is considered. Furthermore, as the Normal distribution is a particulaar case of alpha-stable distribution. Therefore, the proposed approach is also a generalization of the hidden Markov random field segmentation method with Gaussian distributions.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">peis2016mri</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{MRI brain segmentation using hidden Markov random fields with alpha-stable distributions}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Peis, A. Ill{\'a}n, Ignacio and Mart{\'\i}nez-Murcia, Francisco J. and Segovia, Fermín and G{\'o}rriz, Juan M. and Ram{\'\i}rez, Javier and Lang, Elmar W. and Salas-Gonzalez, Diego}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2016 IEEE Nuclear Science Symposium, Medical Imaging Conference and Room-Temperature Semiconductor Detector Workshop (NSS/MIC/RTSD)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--3}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Ignacio Peis. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: April 24, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-repositories",title:"repositories",description:"",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-a-post-with-tabs",title:"a post with tabs",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/tabs/"}},{id:"post-a-post-with-typograms",title:"a post with typograms",description:"this is what included typograms code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/typograms/"}},{id:"post-a-post-that-can-be-cited",title:"a post that can be cited",description:"this is what a post that can be cited looks like",section:"Posts",handler:()=>{window.location.href="/blog/2024/post-citation/"}},{id:"post-a-post-with-pseudo-code",title:"a post with pseudo code",description:"this is what included pseudo code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/pseudocode/"}},{id:"post-a-post-with-code-diff",title:"a post with code diff",description:"this is how you can display code diffs",section:"Posts",handler:()=>{window.location.href="/blog/2024/code-diff/"}},{id:"post-a-post-with-advanced-image-components",title:"a post with advanced image components",description:"this is what advanced image components could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/advanced-images/"}},{id:"post-a-post-with-vega-lite",title:"a post with vega lite",description:"this is what included vega lite code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/vega-lite/"}},{id:"post-a-post-with-geojson",title:"a post with geojson",description:"this is what included geojson code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/geojson-map/"}},{id:"post-a-post-with-echarts",title:"a post with echarts",description:"this is what included echarts code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/echarts/"}},{id:"post-a-post-with-chart-js",title:"a post with chart.js",description:"this is what included chart.js code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/chartjs/"}},{id:"post-a-post-with-tikzjax",title:"a post with TikZJax",description:"this is what included TikZ code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/tikzjax/"}},{id:"post-a-post-with-bibliography",title:"a post with bibliography",description:"an example of a blog post with bibliography",section:"Posts",handler:()=>{window.location.href="/blog/2023/post-bibliography/"}},{id:"post-a-post-with-jupyter-notebook",title:"a post with jupyter notebook",description:"an example of a blog post with jupyter notebook",section:"Posts",handler:()=>{window.location.href="/blog/2023/jupyter-notebook/"}},{id:"post-a-post-with-custom-blockquotes",title:"a post with custom blockquotes",description:"an example of a blog post with custom blockquotes",section:"Posts",handler:()=>{window.location.href="/blog/2023/custom-blockquotes/"}},{id:"post-a-post-with-table-of-contents-on-a-sidebar",title:"a post with table of contents on a sidebar",description:"an example of a blog post with table of contents on a sidebar",section:"Posts",handler:()=>{window.location.href="/blog/2023/sidebar-table-of-contents/"}},{id:"post-a-post-with-audios",title:"a post with audios",description:"this is what included audios could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/audios/"}},{id:"post-a-post-with-videos",title:"a post with videos",description:"this is what included videos could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/videos/"}},{id:"post-displaying-beautiful-tables-with-bootstrap-tables",title:"displaying beautiful tables with Bootstrap Tables",description:"an example of how to use Bootstrap Tables",section:"Posts",handler:()=>{window.location.href="/blog/2023/tables/"}},{id:"post-a-post-with-table-of-contents",title:"a post with table of contents",description:"an example of a blog post with table of contents",section:"Posts",handler:()=>{window.location.href="/blog/2023/table-of-contents/"}},{id:"post-a-post-with-giscus-comments",title:"a post with giscus comments",description:"an example of a blog post with giscus comments",section:"Posts",handler:()=>{window.location.href="/blog/2022/giscus-comments/"}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"post-a-post-with-redirect",title:"a post with redirect",description:"you can also redirect to assets like pdf",section:"Posts",handler:()=>{window.location.href="/assets/pdf/example_pdf.pdf"}},{id:"post-a-post-with-diagrams",title:"a post with diagrams",description:"an example of a blog post with diagrams",section:"Posts",handler:()=>{window.location.href="/blog/2021/diagrams/"}},{id:"post-a-distill-style-blog-post",title:"a distill-style blog post",description:"an example of a distill-style blog post and main elements",section:"Posts",handler:()=>{window.location.href="/blog/2021/distill/"}},{id:"post-a-post-with-twitter",title:"a post with twitter",description:"an example of a blog post with twitter",section:"Posts",handler:()=>{window.location.href="/blog/2020/twitter/"}},{id:"post-a-post-with-disqus-comments",title:"a post with disqus comments",description:"an example of a blog post with disqus comments",section:"Posts",handler:()=>{window.location.href="/blog/2015/disqus-comments/"}},{id:"post-a-post-with-math",title:"a post with math",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/blog/2015/math/"}},{id:"post-a-post-with-code",title:"a post with code",description:"an example of a blog post with some code",section:"Posts",handler:()=>{window.location.href="/blog/2015/code/"}},{id:"post-a-post-with-images",title:"a post with images",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2015/images/"}},{id:"post-a-post-with-formatting-and-links",title:"a post with formatting and links",description:"march &amp; april, looking forward to summer",section:"Posts",handler:()=>{window.location.href="/blog/2015/formatting-and-links/"}},{id:"news-i-will-be-attending-the-machine-learning-summer-school-from-26-aug-to-06-sept-organized-by-the-skolkovo-institute-of-science-amp-amp-technology-in-moscow-russia",title:"I will be attending the Machine Learning Summer School, from 26 Aug to...",description:"",section:"News"},{id:"news-i-will-be-attending-the-1st-mlfpm-summer-school-from-9-to-13-sept-organized-by-the-eth-zurich-in-basel-switzerland",title:"I will be attending the 1st MLFPM Summer School , from 9 to...",description:"",section:"News"},{id:"news-paper-published-deep-sequential-models-for-suicidal-ideation-from-multiple-source-data-in-journal-of-biomedical-and-health-informatics-preprint-paper",title:"Paper published! \u201cDeep Sequential Models for Suicidal Ideation from Multiple Source Data\u201d in...",description:"",section:"News"},{id:"news-i-will-be-attending-the-virtual-gaussian-process-and-uncertainty-quantification-summer-school-from-14-sept-to-17-sept-organized-by-great-researchers-from-the-department-of-computer-science-university-of-sheffield-uk",title:"I will be attending the virtual Gaussian Process and Uncertainty Quantification Summer School,...",description:"",section:"News"},{id:"news-new-preprint-available-on-arxiv-unsupervised-learning-of-global-factors-in-deep-generative-models-prepint-code",title:"New preprint available on arXiv! \u201cUnsupervised Learning of Global Factors in Deep Generative...",description:"",section:"News"},{id:"news-i-started-my-visit-at-the-machine-learning-group-within-the-dept-of-engineering-university-of-cambridge-under-supervision-of-dr-jos\xe9-miguel-hern\xe1ndez-lobato-you-can-find-me-in-the-cbl-lab",title:"I started my visit at the Machine Learning Group within the Dept. of...",description:"",section:"News"},{id:"news-new-preprint-available-on-arxiv-missing-data-imputation-and-acquisition-with-deep-hierarchical-models-and-hamiltonian-monte-carlo-prepint-code",title:"New preprint available on arXiv! \u201cMissing Data Imputation and Acquisition with Deep Hierarchical...",description:"",section:"News"},{id:"news-i-gave-a-talk-to-the-gts-group-at-uc3m-on-hierarchical-vaes-and-hmc-find-here-the-slides",title:"I gave a talk to the GTS group at UC3M on Hierarchical VAEs...",description:"",section:"News"},{id:"news-new-code-release-hamiltonian-monte-carlo-hyperparameter-tuning-implemented-in-pytorch",title:"New code release! Hamiltonian Monte Carlo hyperparameter tuning, implemented in PyTorch.",description:"",section:"News"},{id:"news-i-am-attending-the-ai-and-machine-learning-in-healthcare-summer-school-organised-by-the-cambridge-centre-for-ai-in-medicine",title:"I am attending the AI and Machine Learning in Healthcare Summer School ,...",description:"",section:"News"},{id:"news-our-paper-missing-data-imputation-and-acquisition-with-deep-hierarchical-models-and-hamiltonian-monte-carlo-got-accepted-at-neurips-2022-more-info-soon-prepint-code-slides",title:"Our paper \u201cMissing Data Imputation and Acquisition with Deep Hierarchical Models and Hamiltonian...",description:"",section:"News"},{id:"news-new-paper-accepted-at-pattern-recognition-unsupervised-learning-of-global-factors-in-deep-generative-models-prepint-code",title:"New paper accepted at Pattern Recognition! \u201cUnsupervised Learning of Global Factors in Deep...",description:"",section:"News"},{id:"news-neurips22-hi-from-new-orleans-you-can-find-my-poster-at-hall-j-114-on-wed-30-nov-11-30-a-m-cst-1-p-m-cst-let-s-talk-link-poster-slides-pdf-code",title:"[NeurIPS22] Hi from New Orleans! You can find my poster at Hall J...",description:"",section:"News"},{id:"news-aistats23-i-have-been-selected-as-top-10-reviewer-at-aistats23",title:"[AISTATS23] I have been selected as Top-10% reviewer at AISTATS23  !",description:"",section:"News"},{id:"news-new-preprint-available-on-arxiv-variational-mixture-of-hypergenerators-for-learning-distributions-over-functions-in-this-work-we-leverage-the-advantages-of-vaes-for-learning-distributions-of-functions-via-implicit-neural-representations-prepint",title:"New preprint available on arXiv! \u201cVariational Mixture of HyperGenerators for Learning Distributions Over...",description:"",section:"News"},{id:"news-great-news-our-paper-variational-mixture-of-hypergenerators-for-learning-distributions-over-functions-got-accepted-at-icml-2023-can-t-wait-to-meeting-you-all-at-honolulu-hawai-i-more-info-soon-prepint",title:"Great news! Our paper \u201cVariational Mixture of HyperGenerators for learning distributions over functions\u201d...",description:"",section:"News"},{id:"news-i-have-been-awarded-with-a-postdoc-fellowship-by-the-danish-data-science-academy-ddsa-i-will-join-jes-frellsen-s-group-at-the-technical-university-of-denmark-dtu-denmark-soon-my-project-will-be-funded-by-the-novo-nordisk-foundation",title:"I have been awarded with a Postdoc Fellowship by the Danish Data Science...",description:"",section:"News"},{id:"news-i-gave-a-talk-about-my-recent-research-at-the-pioneer-center-for-artificial-intelligence-in-copenhagen-denmark-find-here-the-slides",title:"I gave a talk about my recent research at the Pioneer Center for...",description:"",section:"News"},{id:"news-aloha-icml23-we-are-presenting-our-paper-come-to-see-our-poster-and-chat-with-us-at-exhibit-hall-1-432-on-thursday-27-jul-at-10-30-am-poster-session-5-\ufe0f-we-will-explain-to-you-how-to-learn-distributions-of-functions-using-a-vae-framework",title:"Aloha ICML23! We are presenting our paper! Come to see our poster and...",description:"",section:"News"},{id:"news-i-successfully-defended-my-phd-thesis-what-an-enriching-experience-thank-you-all-for-your-support-you-can-find-here-the-manuscript-and-the-slides",title:"I successfully defended my PhD thesis! What an enriching experience. Thank you all...",description:"",section:"News"},{id:"news-hi-from-copenhagen-i-started-a-postdoctoral-position-with-jes-frellsen-s-group-at-the-technical-university-of-denmark-dtu-denmark-thanks-again-to-the-danish-data-science-academy-ddsa-and-to-the-novo-nordisk-foundation-for-awarding-my-research-project",title:"Hi from Copenhagen! I started a Postdoctoral position with Jes Frellsen s group...",description:"",section:"News"},{id:"news-i-have-received-the-outstanding-thesis-award-for-my-phd-thesis",title:"I have received the  Outstanding Thesis Award for my PhD thesis!",description:"",section:"News"},{id:"news-i-will-give-a-talk-about-my-recent-research-at-the-first-edition-of-the-andaluz-ia-forum-that-will-be-held-on-wednesday-20th-december-2023-at-pablo-de-olavide-university-in-sevilla-spain-find-here-a-link-to-the-slides",title:"I will give a talk about my recent research at the first edition...",description:"",section:"News"},{id:"news-new-preprint-available-scalable-physical-source-to-field-inference-with-hypernetworks-prepint",title:"New preprint available! \u201cScalable physical source-to-field inference with hypernetworks\u201d   [prepint]",description:"",section:"News"},{id:"news-neurips24-i-have-been-selected-as-top-reviewer-at-neurips-2024",title:"[NeurIPS24] I have been selected as Top Reviewer at NeurIPS 2024!  !",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%69%70%65%61%7A@%64%74%75.%64%6B","_blank")}},{id:"socials-orcid",title:"ORCID",section:"Socials",handler:()=>{window.open("https://orcid.org/0000-0003-4939-2861","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=LGvZev2acusC","_blank")}},{id:"socials-scopus",title:"Scopus",section:"Socials",handler:()=>{window.open("https://www.scopus.com/authid/detail.uri?authorId=57198353823","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/ipeis","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/ignaciopeis","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>